{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e54a3e",
   "metadata": {},
   "source": [
    "# ğŸš€ PhoBERT Fine-tuning on Kaggle (GPU)\n",
    "\n",
    "## âš¡ Kaggle vs Colab:\n",
    "| Feature | Kaggle | Google Colab |\n",
    "|---------|--------|-------------|\n",
    "| **GPU** | P100 (16GB) hoáº·c T4 (16GB) | T4 (15GB) |\n",
    "| **RAM** | 30GB | 12GB |\n",
    "| **Disk** | 73GB | 108GB |\n",
    "| **Time limit** | 12 hours/week | Variable |\n",
    "| **Tá»‘c Ä‘á»™** | âš¡âš¡âš¡ Nhanh hÆ¡n | âš¡âš¡ Trung bÃ¬nh |\n",
    "\n",
    "## ğŸ“¦ Thá»i gian Æ°á»›c tÃ­nh:\n",
    "- **P100 GPU**: ~20-30 phÃºt (3 epochs)\n",
    "- **T4 GPU**: ~30-40 phÃºt (3 epochs)\n",
    "- **TÄƒng tá»‘c vs CPU**: ~60x nhanh hÆ¡n!\n",
    "\n",
    "## ğŸ¯ Báº­t GPU:\n",
    "1. Click **Settings** (âš™ï¸) bÃªn pháº£i\n",
    "2. **Accelerator** â†’ chá»n **GPU P100** hoáº·c **GPU T4**\n",
    "3. Click **Save**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adf956",
   "metadata": {},
   "source": [
    "## ğŸ“¥ BÆ°á»›c 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f23c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo tá»« GitHub\n",
    "!git clone https://github.com/d0ngle8k/NLP-Processing.git\n",
    "%cd NLP-Processing\n",
    "\n",
    "# Xem cáº¥u trÃºc\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb0c89",
   "metadata": {},
   "source": [
    "## ğŸ“¦ BÆ°á»›c 2: CÃ i Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t packages cáº§n thiáº¿t\n",
    "!pip install -q torch transformers underthesea tqdm\n",
    "\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fda247",
   "metadata": {},
   "source": [
    "## ğŸ® BÆ°á»›c 3: Kiá»ƒm Tra GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36107a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” GPU Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"âœ… CUDA Version: {torch.version.cuda}\")\n",
    "    print(\"\\nğŸš€ Ready to train!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No GPU detected!\")\n",
    "    print(\"ğŸ‘‰ Nhá»› báº­t GPU: Settings â†’ Accelerator â†’ GPU P100\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c0ef5",
   "metadata": {},
   "source": [
    "## ğŸ“Š BÆ°á»›c 4: Kiá»ƒm Tra Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Kiá»ƒm tra file tá»“n táº¡i\n",
    "train_file = \"training_data/phobert_training_augmented.json\"\n",
    "\n",
    "if os.path.exists(train_file):\n",
    "    # Load vÃ  Ä‘áº¿m samples\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total = len(data)\n",
    "    train_split = int(0.8 * total)\n",
    "    \n",
    "    print(f\"âœ… Training data found!\")\n",
    "    print(f\"ğŸ“Š Total samples: {total:,}\")\n",
    "    print(f\"ğŸ“Š Training: {train_split:,} (80%)\")\n",
    "    print(f\"ğŸ“Š Validation: {total - train_split:,} (20%)\")\n",
    "    print(f\"\\nğŸ“ Sample data:\")\n",
    "    print(json.dumps(data[0], indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(f\"âŒ Training data not found: {train_file}\")\n",
    "    print(\"ğŸ‘‰ Check if file exists in repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83962b74",
   "metadata": {},
   "source": [
    "## ğŸš€ BÆ°á»›c 5: Báº¯t Äáº§u Training\n",
    "\n",
    "### âš™ï¸ Configuration:\n",
    "- **Epochs**: 3 (cÃ³ thá»ƒ tÄƒng lÃªn 5-10 náº¿u muá»‘n)\n",
    "- **Batch Size**: 16 (P100) hoáº·c 12 (T4)\n",
    "- **Learning Rate**: 2e-5\n",
    "- **Time**: ~20-40 phÃºt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0050655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training vá»›i GPU\n",
    "# P100: batch_size=16, T4: batch_size=12\n",
    "\n",
    "!python train_phobert.py --epochs 3 --batch_size 16\n",
    "\n",
    "# Náº¿u bá»‹ OOM (Out of Memory), giáº£m batch_size:\n",
    "# !python train_phobert.py --epochs 3 --batch_size 12\n",
    "# hoáº·c\n",
    "# !python train_phobert.py --epochs 3 --batch_size 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bcd806",
   "metadata": {},
   "source": [
    "## ğŸ“Š BÆ°á»›c 6: Kiá»ƒm Tra Káº¿t Quáº£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbad720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem training log\n",
    "import os\n",
    "\n",
    "log_file = \"models/phobert_finetuned/training.log\"\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    print(\"ğŸ“„ Training Log:\")\n",
    "    print(\"=\"*60)\n",
    "    with open(log_file, 'r', encoding='utf-8') as f:\n",
    "        print(f.read())\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âš ï¸  Log file not found\")\n",
    "\n",
    "# Xem cÃ¡c file Ä‘Ã£ táº¡o\n",
    "print(\"\\nğŸ“ Model files:\")\n",
    "!ls -lh models/phobert_finetuned/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc5166",
   "metadata": {},
   "source": [
    "## ğŸ“¦ BÆ°á»›c 7: Táº¡o ZIP File Ä‘á»ƒ Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a58dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o zip file\n",
    "!zip -r phobert_finetuned.zip models/phobert_finetuned/\n",
    "\n",
    "# Kiá»ƒm tra kÃ­ch thÆ°á»›c\n",
    "import os\n",
    "zip_size = os.path.getsize('phobert_finetuned.zip') / (1024 * 1024)\n",
    "print(f\"\\nâœ… Zip file created: phobert_finetuned.zip ({zip_size:.1f} MB)\")\n",
    "print(\"\\nğŸ“¥ Download file tá»« Output panel bÃªn pháº£i â†’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd074013",
   "metadata": {},
   "source": [
    "## ğŸ§ª BÆ°á»›c 8: Test Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test model\n",
    "from core_nlp.phobert_model import PhoBERTNLPPipeline\n",
    "\n",
    "# Load fine-tuned model\n",
    "pipeline = PhoBERTNLPPipeline(model_path=\"./models/phobert_finetuned\")\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"mai 8h há»p á»Ÿ phÃ²ng 302\",\n",
    "    \"thá»© 5 tuáº§n sau Ä‘i chÆ¡i\",\n",
    "    \"15/11 sinh nháº­t nháº¯c trÆ°á»›c 2 ngÃ y\",\n",
    "    \"t7 nÃ y 14h30 xem phim táº¡i CGV\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ§ª Testing fine-tuned model:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for text in test_cases:\n",
    "    result = pipeline.extract(text)\n",
    "    print(f\"\\nğŸ“ Input: {text}\")\n",
    "    print(f\"Event: {result.get('event', 'N/A')}\")\n",
    "    print(f\"Time: {result.get('start_time', 'N/A')}\")\n",
    "    print(f\"Location: {result.get('location', 'N/A')}\")\n",
    "    print(f\"Reminder: {result.get('reminder_minutes', 0)} minutes\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ecc63",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Sau Khi Download Model:\n",
    "\n",
    "### 1. Giáº£i nÃ©n file\n",
    "```bash\n",
    "# Windows PowerShell\n",
    "Expand-Archive -Path phobert_finetuned.zip -DestinationPath .\n",
    "\n",
    "# Linux/Mac\n",
    "unzip phobert_finetuned.zip\n",
    "```\n",
    "\n",
    "### 2. Test model local\n",
    "```bash\n",
    "python comprehensive_test.py\n",
    "```\n",
    "\n",
    "### 3. Commit lÃªn GitHub\n",
    "```bash\n",
    "git add models/phobert_finetuned\n",
    "git commit -m \"v1.1.0: Add fine-tuned PhoBERT model\n",
    "\n",
    "- Trained on Kaggle P100 GPU\n",
    "- 76K+ training samples\n",
    "- 3 epochs, ~25 minutes\n",
    "- Expected Macro F1: 90%+\"\n",
    "\n",
    "git push origin main\n",
    "```\n",
    "\n",
    "### 4. Update README\n",
    "```bash\n",
    "# Add to README.md:\n",
    "- âœ… PhoBERT fine-tuned model (90%+ F1)\n",
    "- âœ… Hybrid pipeline with PhoBERT support\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
